\documentclass[a4paper, 11pt]{article}
\usepackage{theme}
\usepackage{shortcuts}
\addbibresource{ref.bib}

\title{Automatic liver segmentation by integrating fully convolutional networks into active contour models}
\author[1, 2]{Ines VATI}
\affil[1]{École des Ponts ParisTech, Champs-sur-Marne, France}
\affil[2]{MVA, ENS Paris-Saclay, Cachan, France}
\affil[1, 2]{Email \email{ines.vati@eleves.enpc.fr}}


\date{}

\begin{document}
\maketitle

\section{Réponses aux questions}

Dans cette première partie, je réponds aux questions demandées en français mais le reste du rapport sera en anglais.

\subsection{Quel est le problème traité ?}
Le problème traité est la segmentation automatique du foie à partir d'images médicales, qui sont notamment des CT scans. La segmentation du foie est une étape cruciale dans le diagnostic et le traitement des maladies du foie. En effet, elle permet de quantifier le volume du foie, de détecter des lésions et de suivre leur évolution. La segmentation manuelle est très fastidieuse et prend beaucoup de temps. 

Les auteurs proposent une méthode de segmentation automatique en intégrant les réseaux de neurones convolutionnels (FCNs) dans les modèles de contours actifs (ACM). 

Un modèle FCN-$8$ est entrainé à predire une carte de distance structurée en couche. Il prédit la couche dans laquelle se trouve chaque pixel de l'image d'entrée. La sortie de ce réseau est utilisée pour définir une force externe $F_{FCN}$ qui est intégrée dans le modèle ACM.  

\subsection{Quelles sont les équations et méthodes numériques utilisées. Peut-on éventuellement donner une formulation plus mathématique au problème ?}

Soient $C$ une courbe et $\varphi$ une fonction Lipschizt tel que 
$C = \{(x, y) | \varphi(x, y) = 0\}$ est le niveau 0 de cette fonction. $\varphi$ est une fonction de distance signée telle que $\varphi(x, y) > 0$ 
si $(x, y)$ est à l'exterieur de l'objet délimité par $C$ et $\varphi(x, y) < 0$ si $(x, y)$ est à l'interieur de $C$.

Nous considérons une bande étroite de pixels adjacents à l'ensemble de niveau zéro $L_0$. Nous définissons les voisinages de $L_0$ en deux types de couches : $L_1, \dots, L_{N-1}$, les couches qui sont à l'extérieur de la structure, et $L_{-1}, \dots, L_{-N+1}$, les couches qui sont à l'intérieur de la structure.

Le réseau de neurones est entrainé à prédire cette carte de label pour une image CT donnée en entrée. \\ 

\textbf{Entrainement du réseau de neurones.} Donnons une formulation mathématique de ce problème. 

$\mathcal{X}\subset \RR^{D\times H\times W} $ est l'espace des images CT. $D$, $H$ et $W$ sont respectivement la profondeur, la hauteur et la largeur de l'image. 

Soit $f_\theta : \mathcal{X} \mapsto \RR^{D\times H\times W\times 2N-1}$ la fonction apprise par le réseau de neurones qui prend en argument une image $I\in\mathcal{X}$. La carte des labels est obtenue en prenant la valeur maximale sur la dernière dimension de $f_{\theta}(I)$ pour chaque voxel.

Entrainer un réseau de neurones consiste à optimiser les poids du réseaux, notés $\theta$, de façon à minimiser une fonction de coût $L$ qui mesure l'écart entre les prédictions du réseau et les vrais labels. Cette optimisation est généralement faite par descente stochastique du gradient.

La sortie du réseau de neurones est généralement normalisée par une fonction d'activation \textit{softmax}. La prediction du réseau $\hat{y}\in\RR^{D\times H\times W\times 2N-1}$ s'écrit alors pour tout $c\in\{1, \dots, 2N-1\}$ et pour tout $X\in \RR^{D\times H\times W}$
$$
\hat{y}_c(X) =  \frac{e^{[f_{\theta}(I)(X)]_c}}{\sum_{i=1}^{2N-1} e^{[f_{\theta}(I)(X)]_i}}
$$

Un fonction de coût classique pour un problème de classification est la cross entropie. Dans le cas où il y a $2N-1$ classes, la fonction de coût est donnée par
\begin{equation}
    L_{CE}(f_{\theta}(I), y) = \sum_{k=1}^{D}\sum_{i=1}^{H}\sum_{j=1}^{W} - \log\left(  \hat{y}_{k,i,j,c}\right) \ones_{\{y_{k,i,j} = c\}}
\end{equation}
où $y\in\RR^{D\times H\times W}$ est la vrai carte de labels de l'image $I$. D'autres fonctions de coût peuvent être utilisées. \\ 

\textbf{Résolution de l'évolution des contours actifs.} Les auteurs proposent une nouvelle force externe notée $F_{FCN}$ à ajouter au modèle de contours actifs basée sur la prédiction du réseau de neurones. Plusieurs choix sont possibles pour ajuster l'amplitude de cette force par rapport à la couche dans laquelle se trouve son point d'application. %Elle peut s'écrite par ex ?

Pour déterminer le contour du foie, les auteurs utilisent la méthode des ensembles de niveaux. Cela revient à résoudre l'équation suivante
$$
\frac{\partial \varphi}{\partial t} = (w_0F_0 + w_1F_{FCN} + \mu\kappa)\overrightarrow{N} \qquad \textrm{où} \quad \kappa = div(\frac{\nabla \varphi}{\norm{\nabla\varphi}})
$$
$\overrightarrow{N}$ est le vecteur normal unitaire du niveau zéro, $C$, de $\varphi$. $w_i$ sont des poids qui permettent de régler l'importance de chaque force. $\mu$ est un paramètre de régularisation. $\kappa$ est la courbure de $C$.
$F_0$ correspond aux forces images conventionnelles. Les auteurs optent pour un modèle de Chan-Vese locale basée région \cite{lankton_localizing_2008}. 

Pour résoudre cette équation, les auteurs utilisent la méthode des champs parcimonieux ou \textit{sparse field method} en anglais, de Whitaker \cite{whitaker_level-set_1998}. 

\subsection{Pouvez-vous situer cet article par rapport aux méthodes étudiées en cours et le comparer à des sujets proches évoqués en cours.}

Cet article se situe dans le cadre de la segmentation d'images médicales, dans la partie du cours qui traite des modèles des contours actifs. 

Nous avons vu dans le cours que cette méthode était très sensible à l'initialisation de la courbe donnée manuellement. En effet, un \textit{snake} qui n'est pas suffisamment proche du bord de l'objet à segmenter n'est pas attiré par lui. Nous avions également noté qu"à cause du bruit certains points isolés, étant des maxima locaux du gradient, pouvaient bloquer la courbe. A l'instar du modèle de ballon, l'ajout de la force externe $F_{FCN}$ rend la méthode proposée plus robuste à l'initialisation en poussant ou tirant la courbe vers le bord de l'objet à segmenter. Contrairement à la force ballon, même si la courbe dépasse le contour d'intérêt, elle est tirée vers le contour. Dans le modèle de ballon, la courbe initiale doit être initialisée à l'intérieur de la structure. Dans le modèle proposé \cite{guo_automatic_2019}, le contour initiale peut être partiellemnent ou complètement à l'intérieur de la structure. Cependant, il ne peut pas étre entièrement à l'extérieur à cause de la présence de fragments parasite dans la carte de distance prédite par le réseau de neurones. 

\subsection{Quelle est l'originalité du travail (selon les auteurs) ?}

Les auteurs proposent d'imposer une force de contrainte externe au modèle des contours actifs en utilisant la sortie d'un réseau de neurones entrainé. L'intérêt de cette nouvelle force externe est que sa direction et son intensité dépendent de la position et de la distance relative du point à la frontière de l'objet à segmenter. Selon sa position (à l'intérieur ou l'extérieur), la force externe tire ou pousse le contour actif vers la frontière de l'objet. De plus, si le point d'application est loin de la frontière, la force est d'autant plus forte. Lorsque le point est proche de la frontière, l'amplitude de la force se réduit laissant les autres forces, comme les forces internes de régularisation et forces image, prendre le dessus et affiner précisément le bord de l'objet. Il joue en quelque sorte le rôle d'un mecanisme d'attention.

Cette nouvelle approche combine des informations de haut niveau grâce à la carte de distance en couche prédite par le réseau de neurones avec des informations de bas niveau issue du modèle ACM classique. L'originalité réside aussi dans le fait que le réseau de neurones n'aurait pas besoin d'étre réentrainé pour chaque nouvelle image, voire pour chaque nouveau dataset (issu d'un autre hopital par exemple). 

\subsection{Quels sont les résultats nouveaux importants qui en découlent ?}

Cette méthode est robuste à l'initialisation du contour actif. La courbe initiale peut être placée loin du bord de la structure à segmenter. Un autre résultat important est que l'intégration des nouvelles méthodes d'apprentissage profond dans les méthodes conventionnelles de segmentation d'images médicales comme les modèles de contours actifs permet d'obtenir de meilleurs résultats.

\subsection{Voyez-vous des faiblesses dans l'approche présentée et avez-vous des idées pour y faire face?}

Les cartes de distances prédites par le réseau de neurones présentes des artifacts. Les réseaux de neurones sont longs à entrainé et requièrent beaucoup de données et de ressources computationnelles. Le pré-entraînement des réseaux de neurones semblent être une solution pour pallier à ce problème. \\ 
De plus la prédiction est sensible à la qualité des données d'entrainement. Les images médicales sont souvent bruitées et peuvent présenter de nombreux artifacts. La \textit{data augmentation} peut être une solution pour rendre les réseaux de neurones robustes à ces variations.

\section{Summary of the project}

\subsection{Turn the binary label map to layered label map}
The first step is to transform a binary image mask, which is a ground truth segmentation map and has only two labels (0 stands for background and 1 for foreground), into a label map with multiple categories (N > 2). Here, the label map contains not only spatial regional information (whether a pixel is on the foreground or background) but also boundary information (whether a pixel is on the object boundary), as well as information about the relative distance to the object boundary.

The structured label map consists of several layers, including narrow band layers near the object boundary, exterior regional layer, and interior regional layer. These layers are nonoverlapping and cover the entire image domain.

Let's consider a narrow band of grid points adjacent to the zero level set as $L_0$ layer. We define the neighborhoods of zero narrow band in two type of layers: $L_1, \dots, L_{N-1}$, the layers that are outside the structure, and $L_{-1}, \dots, L_{-N+1}$, the layers that are inside the structure.

A layer is defined by its distance interval to the zero level set, ie 
$L_i = \lbrace (x, y) | (i-1 - 0.5)\delta \leq \varphi(x, y) \leq (i + 0.5) \delta \rbrace$. For instance, for $N=4$, the layer labels are $\{-3,\ -2,\ -1,\ 0,\ 1,\ 2,\ 3\}$ and
\begin{align*}
    L_{-3} &= \lbrace (x, y) | \infty < \varphi(x, y) < -2.5 \delta \rbrace \\
    L_{-2} &= \lbrace (x, y) | -2.5 \delta < \varphi(x, y) \leq -1.5 \delta \rbrace \\
    L_{-1} &= \lbrace (x, y) | -1.5 \delta < \varphi(x, y) \leq -0.5 \delta \rbrace \\
    L_{0} &= \lbrace (x, y) | -0.5 \delta < \varphi(x, y) \leq 0.5 \delta \rbrace \\
    L_{1} &= \lbrace (x, y) | 0.5 \delta < \varphi(x, y) \leq 1.5 \delta \rbrace \\
    L_{2} &= \lbrace (x, y) | 1.5 \delta < \varphi(x, y) \leq 2.5 \delta \rbrace \\
    L_{3} &= \lbrace (x, y) | 2.5 \delta < \varphi(x, y) \leq \infty \rbrace
\end{align*}

I adopt the same convention as the authors \cite{guo_automatic_2019}. The distance for pixel outside the object (background) is positive and is negative for pixel inside the object (foreground). 

\subsection{Training the neural network}

Mirroring the methodology used in \cite{guo_automatic_2019}, I used the same architecture for the neural network. I use the FCN-8 architecture from \cite{long_fully_2015}. I performed transfer learning by taking the pre-trained model from \url{https://github.com/wkentaro/pytorch-fcn}. This model was trained on the PASCAL VOC dataset comprising 21 classes. I changed the last layers to adapt the model to the new task with $2*N-1$ classes. I trained the model on the Chaos dataset \cite{kavur_chaos_2019}. 

\subsection{Resolution of the Active contour model evolution}
To solve the active contour model, the level set method is used. 

Evolving the curve $C = \ens{(x, y)}{\varphi(x, y) = 0} $ in the normal direction with speed $V$ amount to solve \cite{chan_active_2001}
\begin{equation}\label{levelset_eq}
\left\lbrace \begin{array}{l}
    \frac{\partial \varphi}{\partial t} = V\norm{\nabla \varphi} \\
    \varphi(0, x, y) = \varphi_0(x, y) 
\end{array}
\right.
\end{equation}
$\varphi_0$ is the signed distance to the initial contour defined by the user

External forces can be added to the model to guide the curve towards the object boundary. The authors used the localized regional Chan-Vese model \cite{lankton_localizing_2008} to define the external force $F_0$. They also added the external force $F_{FCN}$ based on the output of the neural network. 

In the particular case of mean curvature motion, the speed $V$ is the curvature of the curve $C$
$$ V = \kappa = \textrm{div}\left(\frac{\nabla\varphi}{\norm{\nabla\varphi}}\right) $$
To solve the equation \ref{levelset_eq}, the authors used the sparse field method of Whitaker \cite{whitaker_level-set_1998}. As seen in the practical session of the class, I used a simple gradient descent.


\subsection{Experiments and Dataset}
As no code was provided, the method and the experiments were implemented from scratch. The implementation is available on \url{https://github.com/InesVATI/active_contour_cnn}.

\textbf{Dataset.} For the experiment, I used a new dataset that was not used by the authors and which presents new challenges. Chaos dataset\footnote{\url{https://chaos.grand-challenge.org/Download/}} \cite{kavur_chaos_2019}. Data corresponds to a series of DICOM images belonging to a single patient. In order to provide sufficient data that contains enough variability to be representative of the problem, the data sets in the training data are selected to represent both the difficulties that are observed on the whole database (e.g. partial volume effects for CT or bias fields for MRI) and examples of the rare but important challenges such as atypical liver shapes (Figures 4 and 5). It only contains healthy livers aligned in the same direction and patient position. However, the challenging part is the enhanced vascular structures (portal phase) due to the contrast injection. Each axial slice has identical size of $512 \times 512$.

\textbf{Experiments.} After training the neural network, I used the output of the neural network to define the external force $F_{FCN}$ in the active contour model. I compared the use of localized and global regional Chan-Vese forces. I also compared the use of the external force $F_{FCN}$ with the external force $F_0$ alone. I also experimented the addition of edge information to the mean curvature motion without noticing any improvement.

\subsection{Conclusion}
As the CT scan were hard to segment, the traditional method did not work. The addition of the external force $F_{FCN}$ improved the results but only because the initial contour were driven towards the boundary defined by the predicted label map. The conventional forces did not contribute in this case. Therefore, the method is sensitive to the quality of the predicted label map. 

To improve the result, a better algorithm to solve the level set equation should be used, like the sparse field method \cite{whitaker_level-set_1998}.

Furthermore, a perspective would be to augment the train dataset with another one like the well known SLIVER07 dataset\footnote{\url{https://sliver07.grand-challenge.org/Home/}}. The data consists of 20 training scans and 10 test scans which, unlike the CHAOS dataset, presents a variety of pathologies.

\printbibliography
\end{document}